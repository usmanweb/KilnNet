# KilnNet
# Implementation Details
We presented detailed experimentation on three classifiers: ResNet-152, Inception-ResNet-v2, Inception-v3 using their default implementations available in [Keras][keraslink]. We also evaluated three detectors: [Faster R-CNN][Faster-R-CNN] , [SSD][SSDlink] and [YOLOv3][YOLOv3link] using their implementations from Github. We note that  any popular object detector can be trained to work on satellite imagery (for example SSD that is presented in the TowardsDataScience article related to [Fighting Pollution using Deep Learning][FightingPollutionusingDeepLearning]). However in our experiments we noted that the average compute time per image of resolution 256x256 for Faster RCNN, SSD, YoloV3 is 1, 0.6 and 0.2 seconds respectively. These numbers are computed using Intel Corei7−7500 UCPU 2.70×2GHz processor, 8 GBs of RAM, and an Nvidia GeForce GTX950MX GPU. This indicates that the overall compute cost of these detectors over the entire Brick-Kiln-Belt of South Asia (i.e. 1,58,936,878  image patches) will be 1840, 1104 and 368 days respectively. Instead, a classifier such as ResNet-152 will take around 92 days only. In other words if we follow the SSD based approach it will take 1104 days as compared to only 93 days using the two-stage Kiln Net method we propose in this paper. Furthermore, there is a higher annotation requirement to train a detector (class information as well as bounding boxes). Thus a detector only approach such as using ArcGIS is infeasible for a large dataset, because of which we propose a coarse-to-fine strategy that aims to filter the bulk of the data using inexpensive classifier while the detector is only applied on small amount of positive detections as to generate localization information while filtering false positives.

[keraslink]: https://keras.io/applications/
[Faster-R-CNN]: https://github.com/tensorflow/models/tree/master/research/object_detection
[SSDlink]: https://github.com/tensorflow/models/tree/master/research/object_detection
[YOLOv3link]: https://github.com/qqwweee/keras-yolo3
[FightingPollutionusingDeepLearning]: https://towardsdatascience.com/fighting-pollution-with-deep-learning-694dd6259b36

# Two Stage Strategy
Although any combination of detector and classifier can be used in the proposed  two-stage strategy we performed a systematic study on trade-off between computational cost and accuracy. We first tested the algorithms on a small portion of data (patches from Kasur (Pakistan), New Delhi (India) and Deh Sabz (Afghanistan)) as shown in Table 5 of the [paper][paperlink]. Based on the F-Beta score we selected the best classifier: ResNet-152 and detector: YOLOv3 as shown in Fig. 7 of the [paper][paperlink]. To further validate this F-Beta based selection we have now added comparison with Faster RCNN and SSD based two stage networks in Table 5 of the [paper][paperlink]. We have also added Fig. 10 and Fig. 11 in the [paper][paperlink] that gives an estimate of the total number of days required and average F1 score for different design choices. It indicates that using a two-stage strategy the entire Brick-Kiln-Belt of South Asia (1,58,936,878 images patches) can be processed in around 3 months as compared to 1-5 years time required by a detector only approach.

[paperlink]: https://ieeexplore.ieee.org/document/9115879

